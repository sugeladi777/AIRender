---
# 赛道与任务概述

本赛道由魔方工作室（暗区突围 / 暗区突围无限）与 MagicDawn 联合主办。目标是用 AI 压缩含不同时刻（Time-of-Day, TOD）光照贴图，既要显著降低资源包体积，又要保证实时解压性能与光照质量——这是衡量方案可落地性的三大核心维度。

赛题分两部分：
- 赛题1（必做）：光照贴图压缩 — 提交压缩文件与解压脚本，按自动评测的客观指标评分（示例：PSNR / SSIM / LPIPS）。
- 赛题2（可选）：将赛题1算法整合进 UE 渲染管线并打包（工程集成与性能验证）。

优先评估指标（按重要性排序，需在实验设计中明确权重）：
- 解压速度（Decompression speed）：关键于实时渲染和游戏端体验，通常要求极低的单帧延迟与可预测的吞吐。
- 压缩率 / 体积（Compression rate / Size）：压缩后存储与分发成本直接受此影响（模型权重 + 表/纹理等）。
- 压缩质量（Reconstruction quality）：客观指标（PSNR / SSIM / LPIPS）与主观视觉感受（尤其 temporally consistent 的表现）。

说明：在给出改进方向时，我会明确说明每种方法在这三项指标上的典型表现与折衷，以便按赛题评分侧重点选择方案。

本文档仅讨论算法/方法与实验流程（不含 UE 集成细节）。目标：给出可执行的优先级路线、实现要点、超参建议与验证方案，便于快速落地与评测。

---

## 0. 现状小结（基线能力与痛点）

基线方法：多分辨率 2D 特征网格（dense）+ 小型 MLP，时间采用 Fourier 编码；训练/推理支持残差模式（默认）。

- 优点（已验证）：
  - 收敛稳定、实现简单、推理速度快、可按层级灵活扩容/裁剪。
  - 残差学习配合 baseline 可显著降低难度，提高细节恢复。
  - 训练脚本、推理脚本、实验脚本已打通，可直接跑大批量实验。
- 不足（待改进）：
  - 体积：网格为 dense 浮点特征，尚未量化/压缩；高层分辨率成本高。
  - 一致性：未启用时间一致性约束，序列可能有轻微闪烁。
  - 交付：缺少统一导出与元信息（metadata），部署格式未固化。

---

## 1. 目标与量化验收标准

以当前最佳训练配置为参考，在近似质量不退的前提下，设定分阶段目标：

- 体积：
  - 短期：仅对网格做 PTQ（8/16bit），总体积下降 ≥ 4×；
  - 中期：叠加 hash-grid（仅替换最高 1–2 层），总体积下降 ≥ 8×。
- 质量：
  - PSNR 下降 ≤ 0.2 dB，LPIPS 增加 ≤ 0.01；
  - Temporal LPIPS 或帧差指标优于当前基线（闪烁降低）。
- 性能：
  - 单帧推理时延无明显回退（±5% 内）；
  - 加载时间可控，内存峰值不升或轻降。

---

## 2. 方案总览（最小侵入式演进）

从下至上三步走：
1) 网格量化（PTQ → QAT，优先实现 PTQ，必要时补 QAT）。
2) 用 hash-grid 替换顶层高分辨率 dense 层（节省大量体积）。
3) 引入时间一致性损失，抑制闪烁；随后可选加入 BaselineEncoder 以进一步压缩静态信息。

所有步骤都配套：配置开关、导出/打包、指标记录与自动化对比（RD 曲线）。

---

## 3. 改进项 A：网格量化（PTQ / QAT）

设计：对每个 level 的特征通道做逐通道线性量化，使用 $(scale, zero\_point)$ 仿射映射；存储为 uint8 或 uint16。必要时通过 QAT 在训练期注入 fake-quant 以恢复质量。

- 训练端：
  - PTQ：离线校准（在验证集随机采样 N 帧位置），统计 per-level/per-channel min/max 或 PWC（percentile）范围。
  - QAT：在 forward 对网格特征插入 fake-quant（STE），建议只对高层或影响最大的层启用，微调 5–20 epoch。
- 推理端：
  - 运行时反量化（或在加载时一次性反量化到 fp16/fp32）；
  - 向量化插值时直接作用于量化后的 lookup + scale。
- 文件结构（示例 metadata.json）：
  - version, model_type, levels, channels_per_level, dtype, scales, zero_points, layout, baseline_path 等。
- 验收：
  - 体积：≥4× 压缩；质量退化满足“目标与量化验收标准”。

---

## 4. 改进项 B：hash-grid 替换顶层 dense 层

动机：最高分辨率层贡献体积最大，但信息冗余高。以固定容量哈希表替代顶层 1–2 层，配合简单冲突融合策略（平均/加权/可学习融合）。

- 实现要点：
  - 索引：$(i,j)\to h(i,j)=\mathrm{mix}(i,j)\bmod M$，M 为哈希容量；
  - 采样：邻近桶插值近似双线性；
  - 冲突：平均 or 小 MLP 融合（首版用平均，简单稳定）。
- 训练策略：
  - 先冻结其余层，单独优化 hash 层若干 epoch，随后全量联合微调；
  - 学习率：hash 层稍高（如 2× grid lr）。
- 存储：
  - metadata 记录 hash 层列表、容量 M、融合策略与随机种子；
  - hash 表按层单独二进制存储，便于替换与对比。
- 验收：
  - 在 PTQ 基础上再降体积 ≥2–4×，质量退化仍满足阈值。

---

## 5. 改进项 C：时间一致性损失（减少闪烁）

在重建损失之外加入时间一致性约束，优先选用帧差一致性（无需光流，低工程量）。

- 损失定义：
  $$
  \mathcal{L}_{temporal} = \mathbb{E}_{(t,t-1)}\left[\,\big\|\,(I_t - I_{t-1}) - (G_t - G_{t-1})\,\big\|_1\right]
  $$
  其中 $I$ 为模型输出，$G$ 为 GT。
- 训练细节：
  - mini-batch 内随机采样相邻时刻 $(t, t\!\pm\!1)$；
  - loss 权重从 0.05 线性 warm-up 到 0.2；
  - 可选：Temporal LPIPS 代替 L1 帧差（质量更稳，速度略慢）。
- 验收：
  - Temporal LPIPS 优于基线，PSNR 无显著下降（≤0.1 dB）。

---

## 6. 改进项 D（可选）：BaselineEncoder（latent texture）

目的：用低分辨率 latent 纹理承载静态空间信息，减轻 grids/MLP 的负担，并利于 8-bit/纹理压缩存储。

- 设计：小型 CNN 编码 baseline→$F_0\in\mathbb{R}^{C\times H/d\times W/d}$；运行时对坐标做双线性采样得到 $f_0(x,y)$，与 grids/time 一起输入 MLP。
- 存储：$F_0$ 以 8-bit 或 BC7 等纹理格式存放；metadata 标注尺度与格式。
- 兼容性：不改动现有残差语义；可作为特征拼接的附加项启用/禁用。
- 验收：
  - 同等体积下质量更高；或在质量持平时体积降低明显。

---

## 7. 导出与打包（提交/集成统一规范）

- 产物：
  - MLP 权重（fp16/fp32 或 int8 weight-only 可选）；
  - grids（量化或 hash）/latent 纹理；
  - baseline.png；metadata.json（版本、布局、量化参数、哈希表信息、归一化约定等）。
- 工具：
  - `scripts/export.py`：一键导出上述文件；
  - `tools/inspect_artifact.py`：打印体积、参数、示例重建；
  - 推理示例：Python 与参考 ONNXRuntime/TorchScript（可选）。

---

## 8. 工程化改动与接口

- 训练脚本：
  - 新增开关：`--ptq/--qat`、`--temporal_loss`、`--hash_top_levels k`、`--baseline_encoder`；
  - 学习率分组：hash/grid/mlp 分开；temporal loss 权重调度参数。
- 实验脚本：
  - 记录与汇总：模型体积（压缩后）、单帧时延、加载时间；
  - 自动绘制 RD 曲线；支持多次重训统计均值/方差。
- 元信息：
  - metadata schema 固化，含校验与版本号；不兼容变更需显式升级 version。

---

## 9. 短期执行计划（2–3 周）

Week 1：PTQ + Temporal
- 实现网格 PTQ 与加载路径（uint8/uint16，per-channel）；
- 加入帧差一致性损失（权重 0.05→0.2）；
- 基础对比：PSNR/LPIPS/Temporal LPIPS/体积/时延。

Week 2：Hash 顶层 + 质量恢复
- 实现最高 1 层 hash-grid，完成 ablation（容量、冲突策略）；
- 若 PTQ 引起质量回退，启用 QAT 微调 10–20 epoch；
- 导出与 metadata 落地，跑 RD 曲线。

Week 3（可选）：BaselineEncoder + 打包
- 实现 BaselineEncoder 原型（C=8–16，d=8–16）与 8-bit 存储；
- 完善 `export.py` 与检查工具；整理提交清单与报告模板。

退出准则：满足第 1 节的体积/质量/时延阈值，并提供完善的导出与评测产物。

---

## 10. 实验设计与指标

- 数据与预算：与当前基线保持一致的训练步数/采样策略；每项设置训练 3 次取均值±方差。
- 指标：PSNR、SSIM、LPIPS、Temporal LPIPS/帧差，模型体积，加载时间，单帧时延。
- 可视化：RD 曲线（体积 vs 质量），延迟-质量散点图，时间一致性对比视频。

---

## 11. 风险与缓解

- 闪烁未改善：提高 temporal 权重到 0.2–0.3；或引入 Temporal LPIPS；必要时轻量滤波后处理（EMA）。
- 量化退化明显：采用 QAT；对关键层改用 16-bit；使用分段/分位数校准。
- Hash 冲突损伤细节：增大容量 M 或仅替换最顶 1 层；引入可学习融合。
- 工程复杂度：逐步开关化，每次只引入一个大改动，配合导出与回滚。

---

## 12. 附：metadata 关键字段（示例）

```
{
  "version": 2,
  "model_type": "GridMLP",
  "residual_mode": true,
  "levels": [16, 32, 64, 128],
  "channels_per_level": 16,
  "quant": {
    "dtype": "uint8",
    "scales": [[... per-level per-channel ...]],
    "zero_points": [[...]]
  },
  "hash": {
    "top_levels": 1,
    "capacity": [262144],
    "seed": 17,
    "merge": "mean"
  },
  "baseline_path": "baseline.png",
  "normalization": {
    "xy_range": "[-1,1]",
    "time": "[0,1]"
  }
}
```

---

以上方案完全基于当前 GridMLP 方法演进，优先保证可落地与可交付；如需，我可以按上述顺序直接提交实现与评测脚本修改。
