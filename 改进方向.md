# 改进方向（YourSrc）

## 当前主要问题
1. ~~**评估阶段引用了不存在的batch参数直接崩溃**（`Train.py` lines 153-166, 408）：命令行解析里没有`--day-batch-size/--night-batch-size`，但`_evaluate_and_save`会调用 `max(self.args.day_batch_size, self.args.night_batch_size)`。目前脚本一旦进评估就抛 `AttributeError`，metrics.csv 永远不会被写入。~~
2. **时间与基线配置被硬编码，无法适配其他数据集**（`Train.py.main`, `LightmapDataLoader.default_times`）：训练始终使用固定的26个时间字符串，并假定必然存在`1200`/`0`两个基线键。如果数据集删减了某些时间或改了命名，`times.index(day_baseline_key)` 会直接报错，训练流程完全不可复用。
3. **训练阶段仍一次性把全部有效样本搬到GPU**（`Train.py::_train_segment_model`）：`inputs = inputs.to(self.device)`后又 `torch.cat([inputs, targets])`，导致坐标与残差各复制一份并常驻显存。单个lightmap可轻松占用几个GB，限制了可并行的图像数量，也完全绕开了DataLoader的prefetch/shuffle能力。
4. **未训练的昼/夜段在评估阶段仍被当作有效模型**（`Train.py.train_one_lightmap` → `_evaluate_and_save`）：当某个segment没有有效像素时不会写`.bin`文件，但评估时依旧重新实例化模型并调用 `_load_model_weights_from_bin`。该函数在找不到文件时默默返回，留下随机初始化权重，却仍参与PSNR/SSIM计算，最终记录毫无意义的数据。
5. **模型文件缺少元数据，Interface只能假定默认超参**（`Interface.py`）：训练脚本允许单独调整`hidden_dim/num_layers/spatial_freq/time_freq`，但导出的`.bin`只包含裸参数和基线。`BasicInterface`始终用默认的256宽度、5层、频率8/4来构建模型，遇到任何非默认超参都会在加载时shape不匹配或产生错误结果，而且用户得不到任何提示。
6. **测试脚本在CUDA路径下无法应用遮罩**（`Test.py` lines 64-86）：`lightmap_reconstruct`保留在GPU，但表达式 `lightmap_reconstruct[:, :, mask <= 0] = 0` 传入的是 NumPy bool 数组。PyTorch 不允许用NumPy索引CUDA Tensor，因而测试在有GPU时会抛 `TypeError`，目前只能在CPU上跑通。
7. **torch.compile被强制开启且无法回退**（`Train.py` parser + `build_model`）：`--use-compile`被声明为`action="store_true"`但默认值却是True，使用者既无法显式关闭，也无法在编译失败时回退到 eager。只要遇到PyTorch<2.0、graph break或非CUDA后端，训练就会直接中断。

## 下一步提升建议
- ~~**补齐批尺寸参数并统一读取路径**：在CLI中新增`--day-batch-size/--night-batch-size`（含合理默认值），`_evaluate_and_save`使用`getattr`带回退，防止metrics阶段因为缺参崩溃。~~
- **从数据配置驱动时间轴与基准**：读取`config.json`里的时间列表/基准键，若缺省再fallback到默认常量，同时在load时给出清晰的错误信息。这能让脚本在不同数据集间复用。
- **实现真正的流式训练**：保留`coords/residual`在CPU（可用`pin_memory=True`），用`TensorDataset+DataLoader`按batch搬运到GPU，并在需要时增加gradient accumulation。这样既能解决显存暴涨，也能重新获得shuffle/并行加载能力。
- **为模型文件写入结构化元数据**：在`.bin`旁保存同名JSON（记录hidden_dim、layer数、频率、归一化、时间列表、代码版本），加载时先比对，必要时拒绝加载并提示用户，Interface也能据此构建正确拓扑。
- **跳过或退化处理未训练的segment**：保存一个标志说明某段没有有效像素；评估和Interface读取到该标志时直接返回基线或跳过记录，避免随机权重污染整体指标。
- **修复Test遮罩和设备对齐问题**：在`Interface.py`中让`get_result()`返回CPU tensor，解决CUDA tensor与numpy索引的兼容性问题。
- **为评测管线添加数值清理**：在`evaluate_and_save`中对`psnr_list/ssim_list/lpips_list`过滤掉NaN/Inf值，避免写入metrics.csv。
- **给torch.compile提供显式开关与版本检测**：把CLI改成`--use-compile/--no-compile`成对参数，默认根据`torch.__version__`和设备类型自动决定；若compile失败应回退到eager并给出warning而不是直接退出。

> 建议优先级：从数据配置驱动时间轴 > 实现流式训练 > 模型元数据与segment处理；compile开关与评测清理可在流程稳定后跟进。
